{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "_cTlKJKhNq7_",
        "outputId": "3f920ede-cf59-4466-e63e-eb637855def3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntorchvision: 画像認識のためのプロジェクト\\nCNN チャネル方法にも畳み込みを計算、得られる特徴量を」特徴マップと呼ぶ\\nストライド：畳み込み演算を適用する間隔\\nパディング：特徴量マップの恥を適当な値で埋める処理、０で埋めることが多い\\nプーリング：機械的にカーネルの値をまとめる\\n\\nカーネルと同じ形のブロックを想定する\\n最大プーリンぎう：ブロック内の最大値を次の層の画素値とする\\n平均プーリング：」ブロック内の平均値\\n\\nプーリング・ストライドを使って特徴マップを縮小させる意味\\n・チャネル数が大きくなるので、計算量を抑える必要がある\\n・特徴量を集約\\n・受容野の拡大（プーリングの方が処理が計量\\n\\nResNet\\n残渣接続・スキップ接続\\n\\n残渣接続の利点\\n・前の層で得られた特徴量を活躍しやすくなる\\n・勾配喪失が起きにくくなる\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "torchvision: 画像認識のためのプロジェクト\n",
        "CNN チャネル方法にも畳み込みを計算、得られる特徴量を」特徴マップと呼ぶ\n",
        "ストライド：畳み込み演算を適用する間隔\n",
        "パディング：特徴量マップの恥を適当な値で埋める処理、０で埋めることが多い\n",
        "プーリング：機械的にカーネルの値をまとめる\n",
        "\n",
        "カーネルと同じ形のブロックを想定する\n",
        "最大プーリンぎう：ブロック内の最大値を次の層の画素値とする\n",
        "平均プーリング：」ブロック内の平均値\n",
        "\n",
        "プーリング・ストライドを使って特徴マップを縮小させる意味\n",
        "・チャネル数が大きくなるので、計算量を抑える必要がある\n",
        "・特徴量を集約\n",
        "・受容野の拡大（プーリングの方が処理が計量\n",
        "\n",
        "ResNet\n",
        "残渣接続・スキップ接続\n",
        "\n",
        "残渣接続の利点\n",
        "・前の層で得られた特徴量を活躍しやすくなる\n",
        "・勾配喪失が起きにくくなる\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Googleドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/python_image_recognition/4_classification/4_2_cnn')\n",
        "\n",
        "import util\n",
        "import eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xonfeaYhSlmM",
        "outputId": "a56fbe38-8e72-4369-8567-4e997d0a1591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "データの標準化に使うへきん・標準偏差の計算処理の実装\n",
        "画像データの標準化は各チャネルで行う\n",
        "'''\n",
        "def get_dataset_statistics(dataset: Dataset):\n",
        "    data = []\n",
        "    for i in range(len(dataset)):\n",
        "        img = dataset[i][0]\n",
        "        data.append(img)\n",
        "    data = torch.stack(data)\n",
        "    channel_mean, channel_std = data.mean(dim=(0,2,3)), data.std(dim=(0,2,3))\n",
        "\n",
        "    return channel_mean, channel_std"
      ],
      "metadata": {
        "id": "AjdbVsOmORox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        stride: int = 1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.downsample = None\n",
        "        if stride > 1: # 残渣接続で特徴マップを縮小する場合、スキップ接続を通る特徴マップを縮小する必要がある\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "\n",
        "        out += x\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "HGjOg35DQ4zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(64, 64),\n",
        "            BasicBlock(64, 64)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(64, 128, stride=2),\n",
        "            BasicBlock(128, 128)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(128, 256, stride=2),\n",
        "            BasicBlock(256, 256)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(256, 512, stride=2),\n",
        "            BasicBlock(512, 512)\n",
        "        )\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1) # 特徴マップの幅・大きさを1\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, return_embed: bool=False):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.flatten(1)\n",
        "\n",
        "        return x if return_embed else self.linear(x)\n",
        "\n",
        "    def get_device(self):\n",
        "        return self.linear.weight.device\n",
        "\n",
        "    def copy(self):\n",
        "        return copy.deepcopy(self)"
      ],
      "metadata": {
        "id": "QfTGc1Rue0Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    '''\n",
        "    ハイパーパラメータとオプションの設定\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.val_ratio = 0.2   # 検証に使う学習セット内のデータの割合\n",
        "        self.num_epochs = 30   # 学習エポック数\n",
        "        self.lr = 1e-2         # 学習率\n",
        "        self.moving_avg = 20   # 移動平均で計算する損失と正確度の値の数\n",
        "        self.batch_size = 32   # バッチサイズ\n",
        "        self.num_workers = 2   # データローダに使うCPUプロセスの数\n",
        "        self.device = 'cuda'   # 学習に使うデバイス\n",
        "        self.num_samples = 200 # t-SNEでプロットするサンプル数\n",
        "\n",
        "def train_eval():\n",
        "    config = Config()\n",
        "\n",
        "    # 入力データ正規化のために学習セットのデータを使って\n",
        "    # 各チャネルの平均と標準偏差を計算\n",
        "    dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=True, download=True,\n",
        "        transform=T.ToTensor())\n",
        "    channel_mean, channel_std = get_dataset_statistics(dataset)\n",
        "\n",
        "    # 画像の整形を行うクラスのインスタンスを用意\n",
        "    transforms = T.Compose((\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=channel_mean, std=channel_std),\n",
        "    ))\n",
        "\n",
        "    # 学習、評価セットの用意\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=True, download=True,\n",
        "        transform=transforms)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=False, download=True,\n",
        "        transform=transforms)\n",
        "\n",
        "    # 学習・検証セットへ分割するためのインデックス集合の生成\n",
        "    val_set, train_set = util.generate_subset(\n",
        "        train_dataset, config.val_ratio)\n",
        "\n",
        "    print(f'学習セットのサンプル数　: {len(train_set)}')\n",
        "    print(f'検証セットのサンプル数　: {len(val_set)}')\n",
        "    print(f'テストセットのサンプル数: {len(test_dataset)}')\n",
        "\n",
        "    # インデックス集合から無作為にインデックスをサンプルするサンプラー\n",
        "    train_sampler = SubsetRandomSampler(train_set)\n",
        "\n",
        "    # DataLoaderを生成\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=config.batch_size,\n",
        "        num_workers=config.num_workers, sampler=train_sampler)\n",
        "    val_loader = DataLoader(\n",
        "        train_dataset, batch_size=config.batch_size,\n",
        "        num_workers=config.num_workers, sampler=val_set)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=config.batch_size,\n",
        "        num_workers=config.num_workers)\n",
        "\n",
        "    # 目的関数の生成\n",
        "    loss_func = F.cross_entropy\n",
        "\n",
        "    # 検証セットの結果による最良モデルの保存用変数\n",
        "    val_loss_best = float('inf')\n",
        "    model_best = None\n",
        "\n",
        "    # ResNet18モデルの生成\n",
        "    model = ResNet18(len(train_dataset.classes))\n",
        "\n",
        "    # モデルを指定デバイスに転送(デフォルトはGPU)\n",
        "    model.to(config.device)\n",
        "\n",
        "    # 最適化器の生成\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.lr)\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        with tqdm(train_loader) as pbar:\n",
        "            pbar.set_description(f'[エポック {epoch + 1}]')\n",
        "\n",
        "            # 移動平均計算用\n",
        "            losses = deque()\n",
        "            accs = deque()\n",
        "            for x, y in pbar:\n",
        "                # データをモデルと同じデバイスに転送\n",
        "                x = x.to(model.get_device())\n",
        "                y = y.to(model.get_device())\n",
        "\n",
        "                # パラメータの勾配をリセット\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝播\n",
        "                y_pred = model(x)\n",
        "\n",
        "                # 学習データに対する損失と正確度を計算\n",
        "                loss = loss_func(y_pred, y)\n",
        "                accuracy = (y_pred.argmax(dim=1) == \\\n",
        "                            y).float().mean()\n",
        "\n",
        "                # 誤差逆伝播\n",
        "                loss.backward()\n",
        "\n",
        "                # パラメータの更新\n",
        "                optimizer.step()\n",
        "\n",
        "                # 移動平均を計算して表示\n",
        "                losses.append(loss.item())\n",
        "                accs.append(accuracy.item())\n",
        "                if len(losses) > config.moving_avg:\n",
        "                    losses.popleft()\n",
        "                    accs.popleft()\n",
        "                pbar.set_postfix({\n",
        "                    'loss': torch.Tensor(losses).mean().item(),\n",
        "                    'accuracy': torch.Tensor(accs).mean().item()})\n",
        "\n",
        "        # 検証セットを使って精度評価\n",
        "        val_loss, val_accuracy = eval.evaluate(\n",
        "            val_loader, model, loss_func)\n",
        "        print(f'検証　: loss = {val_loss:.3f}, '\n",
        "                f'accuracy = {val_accuracy:.3f}')\n",
        "\n",
        "        # より良い検証結果が得られた場合、モデルを記録\n",
        "        if val_loss < val_loss_best:\n",
        "            val_loss_best = val_loss\n",
        "            model_best = model.copy()\n",
        "\n",
        "    # テスト\n",
        "    test_loss, test_accuracy = eval.evaluate(\n",
        "        test_loader, model_best, loss_func)\n",
        "    print(f'テスト: loss = {test_loss:.3f}, '\n",
        "          f'accuracy = {test_accuracy:.3f}')\n",
        "\n",
        "    # t-SNEを使って特徴量の分布をプロット\n",
        "    util.plot_t_sne(test_loader, model_best, config.num_samples)"
      ],
      "metadata": {
        "id": "Cxq5duDRgeHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XbHRIoA-oAOk",
        "outputId": "0c447b2c-118f-4e9a-94ab-7a17a2706481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "学習セットのサンプル数　: 40000\n",
            "検証セットのサンプル数　: 10000\n",
            "テストセットのサンプル数: 10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-8d6533c980f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-5b8ee5103ef5>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# モデルを指定デバイスに転送(デフォルトはGPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# 最適化器の生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     )\n\u001b[0;32m-> 1159\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4JULqXLLoHVh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}